"""
Exemple de Code - IntÃ©gration Mistral AI
DÃ©montre comment le systÃ¨me va fonctionner
"""
import json
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage

# Exemple de configuration
MISTRAL_API_KEY = "your_api_key_here"
client = MistralClient(api_key=MISTRAL_API_KEY)

# Exemple de taxonomie compacte
TAXONOMY_SIMPLIFIED = {
    "localisation": ["Paris", "London", "Dubai", "Tokyo"],
    "budget": ["<5k", "5-10k", "10-15k", "15-25k", "25k+"],
    "urgence": [1, 2, 3, 4, 5],
    "style": ["Casual", "Chic", "Business", "Haute_couture"],
    "couleurs": ["Noir", "Beige", "Cognac", "Bordeaux"]
}

# ========================================
# Ã‰TAPE 1: NETTOYAGE DU TEXTE
# ========================================

def clean_transcript_with_mistral(raw_text: str) -> str:
    """Nettoie une transcription avec Mistral AI"""
    
    prompt_cleaning = f"""Tu es un Ã©diteur expert spÃ©cialisÃ© dans l'analyse de conversations commerciales haut de gamme.

MISSION: Nettoie cette transcription en supprimant:
- Les hÃ©sitations (euh, alors, donc, voilÃ , etc.)
- Les rÃ©pÃ©titions inutiles
- Le bruit conversationnel
- Les Ã©mojis et HTML

IMPORTANT: Conserve INTÃ‰GRALEMENT:
- Tous les termes liÃ©s au luxe, Ã  la mode, aux produits
- Les Ã©motions exprimÃ©es (frustrations, joies, besoins)
- Les dÃ©tails concrets (villes, budgets, Ã©vÃ©nements, professions)
- Les mots-clÃ©s liÃ©s Ã  la personnalisation, exclusivitÃ©, fonctionnalitÃ©

Transcription Ã  nettoyer:
{raw_text}

RÃ©ponds UNIQUEMENT avec le texte nettoyÃ©, sans introduction ni commentaire."""

    response = client.chat(
        model="mistral-large-latest",
        messages=[ChatMessage(role="user", content=prompt_cleaning)],
        temperature=0.3,
        max_tokens=800
    )
    
    return response.choices[0].message.content


# ========================================
# Ã‰TAPE 2: ANALYSE SÃ‰MANTIQUE
# ========================================

def analyze_transcript_with_mistral(cleaned_text: str) -> dict:
    """Analyse une transcription nettoyÃ©e avec Mistral AI"""
    
    # Convertir la taxonomie en JSON pour l'injecter dans le prompt
    taxonomy_json = json.dumps(TAXONOMY_SIMPLIFIED, indent=2, ensure_ascii=False)
    
    prompt_analysis = f"""Tu es l'analyste marketing du projet LVMH Client Profiling.

CONTEXTE: Voici notre taxonomie complÃ¨te de classification client:
{taxonomy_json}

MISSION: Analyse cette transcription nettoyÃ©e et gÃ©nÃ¨re un profil client structurÃ©.

RÃˆGLES STRICTES:
1. Les tags dans "client_tags" doivent UNIQUEMENT provenir de la taxonomie ci-dessus
2. Ne crÃ©e JAMAIS de nouvelles catÃ©gories
3. Si un aspect n'est pas mentionnÃ©, ne l'invente pas
4. Le score d'urgence (1-5) est basÃ© sur:
   - 5: Achat urgent, Ã©vÃ©nement imminent
   - 4: Projet dÃ©fini avec date
   - 3: IntÃ©rÃªt fort, timing flexible
   - 2: Exploration, pas de deadline
   - 1: CuriositÃ© simple

Transcription nettoyÃ©e:
{cleaned_text}

FORMAT DE SORTIE (JSON strict):
{{
  "marketing_summary": "SynthÃ¨se en 1 phrase du besoin client",
  "urgency_score": 1,
  "client_tags": ["tag1", "tag2"],
  "objections": ["objection1", "objection2"]
}}

RÃ©ponds UNIQUEMENT avec le JSON, sans markdown ni commentaire."""

    response = client.chat(
        model="mistral-large-latest",
        messages=[ChatMessage(role="user", content=prompt_analysis)],
        temperature=0.3,
        max_tokens=1000,
        response_format={"type": "json_object"}  # Force JSON output
    )
    
    # Parser la rÃ©ponse JSON
    result = json.loads(response.choices[0].message.content)
    return result


# ========================================
# EXEMPLE D'UTILISATION
# ========================================

if __name__ == "__main__":
    # Transcription sale exemple
    raw_transcript = """
    ğŸŒŸ CLIENTE VIP ğŸŒŸ Mme Dupont ğŸ’¼ entrepreneur â­â­â­â­â­
    Euh donc voilÃ  alors la cliente euh elle a 35 ans environ
    Budget: 8000â‚¬ ğŸ’°ğŸ’°ğŸ’°
    ğŸ  Paris | âœˆï¸ travels a lot
    Elle cherche euh donc un sac pour son mariage dans 2 mois
    Couleur euh noir ou cognac preferred â¤ï¸
    Elle dit que c'est urgent urgent urgent ğŸ“ğŸ“ğŸ“
    """
    
    print("=" * 70)
    print("EXEMPLE - PIPELINE MISTRAL AI")
    print("=" * 70)
    print()
    
    # Ã‰tape 1: Nettoyage
    print("ğŸ§¹ NETTOYAGE...")
    cleaned = clean_transcript_with_mistral(raw_transcript)
    print(f"Texte nettoyÃ©: {cleaned}")
    print()
    
    # Ã‰tape 2: Analyse
    print("ğŸ” ANALYSE...")
    analysis = analyze_transcript_with_mistral(cleaned)
    print("RÃ©sultat JSON:")
    print(json.dumps(analysis, indent=2, ensure_ascii=False))
    print()
    
    print("âœ… Pipeline terminÃ©!")
    
    # Exemple de sortie attendue:
    """
    {
      "marketing_summary": "Cliente VIP cherche un sac de luxe pour son mariage dans 2 mois, budget 8kâ‚¬",
      "urgency_score": 4,
      "client_tags": ["Paris", "5-10k", "Noir", "Cognac", "Business"],
      "objections": []
    }
    """
